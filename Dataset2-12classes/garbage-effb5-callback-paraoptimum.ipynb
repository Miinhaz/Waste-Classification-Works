{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\nimport numpy as np\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom efficientnet.keras import EfficientNetB5\nfrom tensorflow.keras.layers import BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-13T08:32:07.096325Z","iopub.execute_input":"2023-07-13T08:32:07.096710Z","iopub.status.idle":"2023-07-13T08:32:29.445185Z","shell.execute_reply.started":"2023-07-13T08:32:07.096676Z","shell.execute_reply":"2023-07-13T08:32:29.443706Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the path to the dataset\ndata_path = '/kaggle/input/garbage-classification/garbage_classification'\n\ndef load_images(path, target_shape):\n    X = []\n    y = []\n    for folder in os.listdir(path):\n        if os.path.isdir(os.path.join(path, folder)):\n            folder_path = os.path.join(path, folder)\n            for image_file in os.listdir(folder_path):\n                image_path = os.path.join(folder_path, image_file)\n                image = cv2.imread(image_path)\n                resized_image = cv2.resize(image, target_shape[:2])\n                X.append(resized_image)\n                y.append(folder)\n    X = np.array(X)\n    y = np.array(y)\n    return X, y\n\n# Set the target shape for input images\ntarget_shape = (90, 90, 3)\n\n# Load and preprocess the data\nX, y = load_images(data_path, target_shape)\nnum_classes = len(np.unique(y))\ny = to_categorical(LabelEncoder().fit_transform(y))\n\n# Split the dataset into training, validation, and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-13T08:34:30.420457Z","iopub.execute_input":"2023-07-13T08:34:30.421155Z","iopub.status.idle":"2023-07-13T08:36:24.063101Z","shell.execute_reply.started":"2023-07-13T08:34:30.421115Z","shell.execute_reply":"2023-07-13T08:36:24.062101Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Construct the EfficientNetB5 model\nbase_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=target_shape, pooling='max')\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n    Dense(256, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n    Dropout(rate=0.45, seed=123),\n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-13T08:36:29.935108Z","iopub.execute_input":"2023-07-13T08:36:29.935472Z","iopub.status.idle":"2023-07-13T08:36:42.204228Z","shell.execute_reply.started":"2023-07-13T08:36:29.935442Z","shell.execute_reply":"2023-07-13T08:36:42.203276Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n115515256/115515256 [==============================] - 2s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnet-b5 (Functional  (None, 2048)             28513520  \n )                                                               \n                                                                 \n batch_normalization (BatchN  (None, 2048)             8192      \n ormalization)                                                   \n                                                                 \n dense (Dense)               (None, 256)               524544    \n                                                                 \n dropout (Dropout)           (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 12)                3084      \n                                                                 \n=================================================================\nTotal params: 29,049,340\nTrainable params: 28,872,508\nNon-trainable params: 176,832\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.patience = patience\n        self.stop_patience = stop_patience\n        self.threshold = threshold\n        self.factor = factor\n        self.batches = batches\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch\n\n        self.count = 0\n        self.stop_count = 0\n        self.best_epoch = 1\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr))\n        self.highest_tracc = 0.0\n        self.lowest_vloss = np.inf\n        self.best_weights = self.model.get_weights()\n        self.initial_weights = self.model.get_weights()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.batches == 0 and epoch > 0:\n            tr_acc = logs.get('accuracy')\n            v_loss = logs.get('val_loss')\n\n            if tr_acc > self.highest_tracc:\n                self.highest_tracc = tr_acc\n\n            if v_loss < self.lowest_vloss:\n                self.lowest_vloss = v_loss\n                self.best_epoch = epoch + 1\n                self.best_weights = self.model.get_weights()\n                self.count = 0\n            else:\n                self.count += 1\n\n            if tr_acc >= self.threshold:\n                self.ask_epoch -= 1\n\n            if self.count == self.patience and self.ask_epoch > 0:\n                print(\"\\nEpoch %d: Accuracy threshold reached. Decreasing learning rate.\" % (epoch + 1))\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                new_lr = old_lr * self.factor\n                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n                print(\"Learning rate decreased from %f to %f\" % (old_lr, new_lr))\n                self.count = 0\n\n            if self.count == self.patience and self.ask_epoch == 0:\n                self.stop_count += 1\n                if self.stop_count == self.stop_patience:\n                    print(\"\\nTraining stopped at epoch %d\" % (epoch + 1))\n                    self.model.stop_training = True\n                else:\n                    print(\"\\nEpoch %d: Learning rate adjustment limit reached. Restoring best weights.\" % (epoch + 1))\n                    self.model.set_weights(self.best_weights)\n                    self.count = 0","metadata":{"execution":{"iopub.status.busy":"2023-07-13T08:36:47.182776Z","iopub.execute_input":"2023-07-13T08:36:47.183620Z","iopub.status.idle":"2023-07-13T08:36:47.198762Z","shell.execute_reply.started":"2023-07-13T08:36:47.183580Z","shell.execute_reply":"2023-07-13T08:36:47.197734Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define the callbacks\ncheckpoint = ModelCheckpoint('/kaggle/working/best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nmy_callback = MyCallback(model=model, patience=10, stop_patience=5, threshold=0.9, factor=0.1, batches=10, epochs=100, ask_epoch=10)\n\n# Train the model\nhistory = model.fit(X_train, y_train, batch_size=8, epochs=20, validation_data=(X_val, y_val), callbacks=[checkpoint, my_callback])\n\n# Load the best weights\nmodel.load_weights('/kaggle/working/best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-07-13T09:31:18.641968Z","iopub.execute_input":"2023-07-13T09:31:18.642415Z","iopub.status.idle":"2023-07-13T10:19:42.391256Z","shell.execute_reply.started":"2023-07-13T09:31:18.642381Z","shell.execute_reply":"2023-07-13T10:19:42.390268Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9870\nEpoch 1: val_accuracy improved from -inf to 0.93398, saving model to /kaggle/working/best_model.h5\n1397/1397 [==============================] - 144s 103ms/step - loss: 0.2296 - accuracy: 0.9870 - val_loss: 0.4337 - val_accuracy: 0.9340\nEpoch 2/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9855\nEpoch 2: val_accuracy improved from 0.93398 to 0.93639, saving model to /kaggle/working/best_model.h5\n1397/1397 [==============================] - 145s 104ms/step - loss: 0.2284 - accuracy: 0.9855 - val_loss: 0.4037 - val_accuracy: 0.9364\nEpoch 3/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9876\nEpoch 3: val_accuracy did not improve from 0.93639\n1397/1397 [==============================] - 140s 100ms/step - loss: 0.2135 - accuracy: 0.9876 - val_loss: 0.4118 - val_accuracy: 0.9332\nEpoch 4/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9886\nEpoch 4: val_accuracy did not improve from 0.93639\n1397/1397 [==============================] - 144s 103ms/step - loss: 0.2066 - accuracy: 0.9886 - val_loss: 0.4458 - val_accuracy: 0.9300\nEpoch 5/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9886\nEpoch 5: val_accuracy did not improve from 0.93639\n1397/1397 [==============================] - 139s 100ms/step - loss: 0.2018 - accuracy: 0.9886 - val_loss: 0.3981 - val_accuracy: 0.9364\nEpoch 6/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9903\nEpoch 6: val_accuracy improved from 0.93639 to 0.93881, saving model to /kaggle/working/best_model.h5\n1397/1397 [==============================] - 144s 103ms/step - loss: 0.1887 - accuracy: 0.9903 - val_loss: 0.3819 - val_accuracy: 0.9388\nEpoch 7/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9901\nEpoch 7: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 140s 100ms/step - loss: 0.1821 - accuracy: 0.9901 - val_loss: 0.3636 - val_accuracy: 0.9380\nEpoch 8/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9908\nEpoch 8: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 141s 101ms/step - loss: 0.1811 - accuracy: 0.9908 - val_loss: 0.4044 - val_accuracy: 0.9380\nEpoch 9/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9902\nEpoch 9: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 140s 100ms/step - loss: 0.1754 - accuracy: 0.9902 - val_loss: 0.4574 - val_accuracy: 0.9324\nEpoch 10/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9902\nEpoch 10: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1784 - accuracy: 0.9902 - val_loss: 0.4037 - val_accuracy: 0.9372\nEpoch 11/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9918\nEpoch 11: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1718 - accuracy: 0.9918 - val_loss: 0.4011 - val_accuracy: 0.9372\nEpoch 12/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9922\nEpoch 12: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1614 - accuracy: 0.9922 - val_loss: 0.3661 - val_accuracy: 0.9380\nEpoch 13/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9934\nEpoch 13: val_accuracy did not improve from 0.93881\n1397/1397 [==============================] - 141s 101ms/step - loss: 0.1589 - accuracy: 0.9934 - val_loss: 0.4091 - val_accuracy: 0.9316\nEpoch 14/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9919\nEpoch 14: val_accuracy improved from 0.93881 to 0.94444, saving model to /kaggle/working/best_model.h5\n1397/1397 [==============================] - 144s 103ms/step - loss: 0.1609 - accuracy: 0.9919 - val_loss: 0.3365 - val_accuracy: 0.9444\nEpoch 15/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9927\nEpoch 15: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1510 - accuracy: 0.9927 - val_loss: 0.3657 - val_accuracy: 0.9412\nEpoch 16/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9934\nEpoch 16: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1478 - accuracy: 0.9934 - val_loss: 0.3651 - val_accuracy: 0.9388\nEpoch 17/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9915\nEpoch 17: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 143s 103ms/step - loss: 0.1533 - accuracy: 0.9915 - val_loss: 0.3716 - val_accuracy: 0.9396\nEpoch 18/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9944\nEpoch 18: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 143s 102ms/step - loss: 0.1404 - accuracy: 0.9944 - val_loss: 0.3778 - val_accuracy: 0.9396\nEpoch 19/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9919\nEpoch 19: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 142s 102ms/step - loss: 0.1503 - accuracy: 0.9919 - val_loss: 0.3720 - val_accuracy: 0.9348\nEpoch 20/20\n1397/1397 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9957\nEpoch 20: val_accuracy did not improve from 0.94444\n1397/1397 [==============================] - 143s 102ms/step - loss: 0.1342 - accuracy: 0.9957 - val_loss: 0.3007 - val_accuracy: 0.9444\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate predictions for the test set\ny_pred = model.predict(X_test)\ny_pred_labels = np.argmax(y_pred, axis=1)\ny_true_labels = np.argmax(y_test, axis=1)\n\n# Convert integer labels to class names\nclass_names = sorted(os.listdir(data_path))\ny_true_names = np.array(class_names)[y_true_labels]\ny_pred_names = np.array(class_names)[y_pred_labels]\n\n# Generate and print the classification report\nreport = classification_report(y_true_names, y_pred_names)\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T09:30:33.114344Z","iopub.execute_input":"2023-07-13T09:30:33.114756Z","iopub.status.idle":"2023-07-13T09:30:37.033645Z","shell.execute_reply.started":"2023-07-13T09:30:33.114725Z","shell.execute_reply":"2023-07-13T09:30:37.032520Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"97/97 [==============================] - 4s 37ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n     battery       0.90      0.96      0.93       188\n  biological       0.93      0.96      0.94       196\n brown-glass       0.95      0.90      0.92       135\n   cardboard       0.96      0.90      0.93       186\n     clothes       0.99      0.98      0.99      1076\n green-glass       0.97      0.93      0.95       119\n       metal       0.89      0.84      0.87       159\n       paper       0.92      0.96      0.94       204\n     plastic       0.86      0.80      0.83       157\n       shoes       0.93      0.96      0.94       394\n       trash       0.94      0.94      0.94       142\n white-glass       0.86      0.92      0.89       147\n\n    accuracy                           0.94      3103\n   macro avg       0.92      0.92      0.92      3103\nweighted avg       0.94      0.94      0.94      3103\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test loss:\", test_loss)\nprint(\"Test accuracy:\", test_accuracy)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T10:20:39.216425Z","iopub.execute_input":"2023-07-13T10:20:39.217384Z","iopub.status.idle":"2023-07-13T10:20:44.586063Z","shell.execute_reply.started":"2023-07-13T10:20:39.217345Z","shell.execute_reply":"2023-07-13T10:20:44.584273Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"97/97 [==============================] - 4s 42ms/step - loss: 0.3691 - accuracy: 0.9368\nTest loss: 0.3690968155860901\nTest accuracy: 0.9368353486061096\n","output_type":"stream"}]}]}