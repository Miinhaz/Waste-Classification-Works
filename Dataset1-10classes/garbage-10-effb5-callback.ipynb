{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\nimport numpy as np\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom efficientnet.keras import EfficientNetB5\nfrom tensorflow.keras.layers import BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-14T17:03:42.167587Z","iopub.execute_input":"2023-07-14T17:03:42.168227Z","iopub.status.idle":"2023-07-14T17:04:05.246246Z","shell.execute_reply.started":"2023-07-14T17:03:42.168192Z","shell.execute_reply":"2023-07-14T17:04:05.245088Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.20.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the path to the dataset\ndata_path = '/kaggle/input/garbage-classification-v2/Garbage Classification'\n\ndef load_images(path, target_shape):\n    X = []\n    y = []\n    for folder in os.listdir(path):\n        if os.path.isdir(os.path.join(path, folder)):\n            folder_path = os.path.join(path, folder)\n            for image_file in os.listdir(folder_path):\n                image_path = os.path.join(folder_path, image_file)\n                try:\n                    image = cv2.imread(image_path)\n                    if image is None:\n                        continue  # Skip non-image files\n                    resized_image = cv2.resize(image, target_shape[:2])\n                    X.append(resized_image)\n                    y.append(folder)\n                except Exception as e:\n                    print(f\"Error processing image: {image_path} - {e}\")\n    X = np.array(X)\n    y = np.array(y)\n    return X, y\n\n\n# Set the target shape for input images\ntarget_shape = (90, 90, 3)\n\n# Load and preprocess the data\nX, y = load_images(data_path, target_shape)\nnum_classes = len(np.unique(y))\ny = to_categorical(LabelEncoder().fit_transform(y))\n\n# Split the dataset into training, validation, and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:09:35.083963Z","iopub.execute_input":"2023-07-14T17:09:35.084981Z","iopub.status.idle":"2023-07-14T17:11:24.679674Z","shell.execute_reply.started":"2023-07-14T17:09:35.084944Z","shell.execute_reply":"2023-07-14T17:11:24.678679Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"libpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\n","output_type":"stream"}]},{"cell_type":"code","source":"# Construct the EfficientNetB5 model\nbase_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=target_shape, pooling='max')\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n    Dense(256, kernel_regularizer=regularizers.l2(l=0.016), activity_regularizer=regularizers.l1(0.006),\n          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n    Dropout(rate=0.45, seed=123),\n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:11:32.443879Z","iopub.execute_input":"2023-07-14T17:11:32.444461Z","iopub.status.idle":"2023-07-14T17:11:44.968646Z","shell.execute_reply.started":"2023-07-14T17:11:32.444418Z","shell.execute_reply":"2023-07-14T17:11:44.967684Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n115515256/115515256 [==============================] - 2s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnet-b5 (Functional  (None, 2048)             28513520  \n )                                                               \n                                                                 \n batch_normalization (BatchN  (None, 2048)             8192      \n ormalization)                                                   \n                                                                 \n dense (Dense)               (None, 256)               524544    \n                                                                 \n dropout (Dropout)           (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 29,048,826\nTrainable params: 28,871,994\nNon-trainable params: 176,832\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def __init__(self, model, patience, stop_patience, threshold, factor, batches, epochs, ask_epoch):\n        super(MyCallback, self).__init__()\n        self.model = model\n        self.patience = patience\n        self.stop_patience = stop_patience\n        self.threshold = threshold\n        self.factor = factor\n        self.batches = batches\n        self.epochs = epochs\n        self.ask_epoch = ask_epoch\n        self.ask_epoch_initial = ask_epoch\n\n        self.count = 0\n        self.stop_count = 0\n        self.best_epoch = 1\n        self.initial_lr = float(tf.keras.backend.get_value(model.optimizer.lr))\n        self.highest_tracc = 0.0\n        self.lowest_vloss = np.inf\n        self.best_weights = self.model.get_weights()\n        self.initial_weights = self.model.get_weights()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.batches == 0 and epoch > 0:\n            tr_acc = logs.get('accuracy')\n            v_loss = logs.get('val_loss')\n\n            if tr_acc > self.highest_tracc:\n                self.highest_tracc = tr_acc\n\n            if v_loss < self.lowest_vloss:\n                self.lowest_vloss = v_loss\n                self.best_epoch = epoch + 1\n                self.best_weights = self.model.get_weights()\n                self.count = 0\n            else:\n                self.count += 1\n\n            if tr_acc >= self.threshold:\n                self.ask_epoch -= 1\n\n            if self.count == self.patience and self.ask_epoch > 0:\n                print(\"\\nEpoch %d: Accuracy threshold reached. Decreasing learning rate.\" % (epoch + 1))\n                old_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n                new_lr = old_lr * self.factor\n                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n                print(\"Learning rate decreased from %f to %f\" % (old_lr, new_lr))\n                self.count = 0\n\n            if self.count == self.patience and self.ask_epoch == 0:\n                self.stop_count += 1\n                if self.stop_count == self.stop_patience:\n                    print(\"\\nTraining stopped at epoch %d\" % (epoch + 1))\n                    self.model.stop_training = True\n                else:\n                    print(\"\\nEpoch %d: Learning rate adjustment limit reached. Restoring best weights.\" % (epoch + 1))\n                    self.model.set_weights(self.best_weights)\n                    self.count = 0","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:11:49.886551Z","iopub.execute_input":"2023-07-14T17:11:49.886956Z","iopub.status.idle":"2023-07-14T17:11:49.904542Z","shell.execute_reply.started":"2023-07-14T17:11:49.886925Z","shell.execute_reply":"2023-07-14T17:11:49.903503Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define the callbacks\ncheckpoint = ModelCheckpoint('/kaggle/working/best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nmy_callback = MyCallback(model=model, patience=10, stop_patience=5, threshold=0.9, factor=0.1, batches=10, epochs=100, ask_epoch=10)\n\n# Train the model\nhistory = model.fit(X_train, y_train, batch_size=8, epochs=20, validation_data=(X_val, y_val), callbacks=[checkpoint, my_callback])\n\n# Load the best weights\nmodel.load_weights('/kaggle/working/best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:11:55.278837Z","iopub.execute_input":"2023-07-14T17:11:55.279206Z","iopub.status.idle":"2023-07-14T18:18:52.237434Z","shell.execute_reply.started":"2023-07-14T17:11:55.279174Z","shell.execute_reply":"2023-07-14T18:18:52.236402Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2023-07-14 17:12:38.292209: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnet-b5/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"1979/1979 [==============================] - ETA: 0s - loss: 5.3081 - accuracy: 0.6395\nEpoch 1: val_accuracy improved from -inf to 0.84764, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 305s 101ms/step - loss: 5.3081 - accuracy: 0.6395 - val_loss: 2.1692 - val_accuracy: 0.8476\nEpoch 2/20\n1979/1979 [==============================] - ETA: 0s - loss: 1.5994 - accuracy: 0.7914\nEpoch 2: val_accuracy improved from 0.84764 to 0.89596, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 198s 100ms/step - loss: 1.5994 - accuracy: 0.7914 - val_loss: 0.9184 - val_accuracy: 0.8960\nEpoch 3/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.9269 - accuracy: 0.8521\nEpoch 3: val_accuracy improved from 0.89596 to 0.93348, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 200s 101ms/step - loss: 0.9269 - accuracy: 0.8521 - val_loss: 0.6324 - val_accuracy: 0.9335\nEpoch 4/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.8874\nEpoch 4: val_accuracy did not improve from 0.93348\n1979/1979 [==============================] - 197s 100ms/step - loss: 0.7302 - accuracy: 0.8874 - val_loss: 0.5987 - val_accuracy: 0.9193\nEpoch 5/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.9170\nEpoch 5: val_accuracy did not improve from 0.93348\n1979/1979 [==============================] - 195s 99ms/step - loss: 0.5931 - accuracy: 0.9170 - val_loss: 0.5351 - val_accuracy: 0.9335\nEpoch 6/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.9350\nEpoch 6: val_accuracy did not improve from 0.93348\n1979/1979 [==============================] - 195s 98ms/step - loss: 0.5055 - accuracy: 0.9350 - val_loss: 0.5258 - val_accuracy: 0.9306\nEpoch 7/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.9460\nEpoch 7: val_accuracy improved from 0.93348 to 0.94315, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 199s 100ms/step - loss: 0.4456 - accuracy: 0.9460 - val_loss: 0.4380 - val_accuracy: 0.9431\nEpoch 8/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.9596\nEpoch 8: val_accuracy did not improve from 0.94315\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.3860 - accuracy: 0.9596 - val_loss: 0.4589 - val_accuracy: 0.9375\nEpoch 9/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.9628\nEpoch 9: val_accuracy did not improve from 0.94315\n1979/1979 [==============================] - 191s 97ms/step - loss: 0.3585 - accuracy: 0.9628 - val_loss: 0.4184 - val_accuracy: 0.9397\nEpoch 10/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.9707\nEpoch 10: val_accuracy did not improve from 0.94315\n1979/1979 [==============================] - 193s 97ms/step - loss: 0.3123 - accuracy: 0.9707 - val_loss: 0.4083 - val_accuracy: 0.9426\nEpoch 11/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.9738\nEpoch 11: val_accuracy did not improve from 0.94315\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.2906 - accuracy: 0.9738 - val_loss: 0.4147 - val_accuracy: 0.9414\nEpoch 12/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9777\nEpoch 12: val_accuracy improved from 0.94315 to 0.94542, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 197s 99ms/step - loss: 0.2691 - accuracy: 0.9777 - val_loss: 0.3641 - val_accuracy: 0.9454\nEpoch 13/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.9815\nEpoch 13: val_accuracy improved from 0.94542 to 0.95054, saving model to /kaggle/working/best_model.h5\n1979/1979 [==============================] - 195s 99ms/step - loss: 0.2436 - accuracy: 0.9815 - val_loss: 0.3699 - val_accuracy: 0.9505\nEpoch 14/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9800\nEpoch 14: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.2394 - accuracy: 0.9800 - val_loss: 0.3815 - val_accuracy: 0.9420\nEpoch 15/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9841\nEpoch 15: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.2212 - accuracy: 0.9841 - val_loss: 0.3810 - val_accuracy: 0.9369\nEpoch 16/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9864\nEpoch 16: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.2056 - accuracy: 0.9864 - val_loss: 0.3999 - val_accuracy: 0.9409\nEpoch 17/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9831\nEpoch 17: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 197s 99ms/step - loss: 0.2137 - accuracy: 0.9831 - val_loss: 0.3931 - val_accuracy: 0.9443\nEpoch 18/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9877\nEpoch 18: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.1948 - accuracy: 0.9877 - val_loss: 0.3804 - val_accuracy: 0.9403\nEpoch 19/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9888\nEpoch 19: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.1798 - accuracy: 0.9888 - val_loss: 0.3706 - val_accuracy: 0.9420\nEpoch 20/20\n1979/1979 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9886\nEpoch 20: val_accuracy did not improve from 0.95054\n1979/1979 [==============================] - 194s 98ms/step - loss: 0.1777 - accuracy: 0.9886 - val_loss: 0.3850 - val_accuracy: 0.9443\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test loss:\", test_loss)\nprint(\"Test accuracy:\", test_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T18:19:10.720107Z","iopub.execute_input":"2023-07-14T18:19:10.720507Z","iopub.status.idle":"2023-07-14T18:19:21.147368Z","shell.execute_reply.started":"2023-07-14T18:19:10.720474Z","shell.execute_reply":"2023-07-14T18:19:21.146386Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"138/138 [==============================] - 6s 43ms/step - loss: 0.3485 - accuracy: 0.9495\nTest loss: 0.3485081195831299\nTest accuracy: 0.9495110511779785\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate predictions for the test set\ny_pred = model.predict(X_test)\ny_pred_labels = np.argmax(y_pred, axis=1)\ny_true_labels = np.argmax(y_test, axis=1)\n\n# Convert integer labels to class names\nclass_names = sorted(os.listdir(data_path))\ny_true_names = np.array(class_names)[y_true_labels]\ny_pred_names = np.array(class_names)[y_pred_labels]\n\n# Generate and print the classification report\nreport = classification_report(y_true_names, y_pred_names)\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T18:19:38.924361Z","iopub.execute_input":"2023-07-14T18:19:38.925061Z","iopub.status.idle":"2023-07-14T18:19:48.593503Z","shell.execute_reply.started":"2023-07-14T18:19:38.925018Z","shell.execute_reply":"2023-07-14T18:19:48.592323Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"138/138 [==============================] - 9s 38ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n     battery       0.96      0.92      0.94       185\n  biological       0.94      0.95      0.94       235\n   cardboard       0.96      0.95      0.95       389\n     clothes       0.99      0.98      0.98      1065\n       glass       0.97      0.93      0.95       792\n       metal       0.84      0.95      0.89       346\n       paper       0.92      0.96      0.94       421\n     plastic       0.94      0.92      0.93       445\n       shoes       0.95      0.94      0.95       387\n       trash       0.95      0.92      0.94       132\n\n    accuracy                           0.95      4397\n   macro avg       0.94      0.94      0.94      4397\nweighted avg       0.95      0.95      0.95      4397\n\n","output_type":"stream"}]}]}