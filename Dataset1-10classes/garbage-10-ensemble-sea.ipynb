{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport cv2\nimport os\nimport numpy as np\nfrom keras.utils import np_utils\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Activation, GlobalAveragePooling2D, Dropout, Conv2D, BatchNormalization, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom tensorflow.keras.applications.densenet import DenseNet201, DenseNet169\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Reshape, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Input, GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import multiply, GlobalAveragePooling2D","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-23T11:48:37.190228Z","iopub.execute_input":"2023-07-23T11:48:37.190624Z","iopub.status.idle":"2023-07-23T11:48:46.515030Z","shell.execute_reply.started":"2023-07-23T11:48:37.190580Z","shell.execute_reply":"2023-07-23T11:48:46.513992Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/garbage-classification-v2/Garbage Classification'\n\ndef load_dataset(path, target_shape):\n    class_folders = os.listdir(path)\n    filenames = []\n    labels = []\n\n    for i, class_folder in enumerate(class_folders):\n        folder_path = os.path.join(path, class_folder)\n        for filename in os.listdir(folder_path):\n            image_path = os.path.join(folder_path, filename)\n            try:\n                image = cv2.imread(image_path)\n                if image is None:\n                    continue  # Skip non-image files\n                resized_image = cv2.resize(image, target_shape[:2])\n                filenames.append(resized_image)\n                labels.append(i)\n            except Exception as e:\n                print(f\"Error processing image: {image_path} - {e}\")\n\n    X = np.array(filenames)\n    y = np.array(labels)\n\n    # Normalize pixel values\n    X = X.astype('float32') / 255.0\n\n    # Convert labels to categorical\n    y = np_utils.to_categorical(y)\n\n    return X, y\n\n\n# Define the target shape for resizing images\ntarget_shape = (95, 95, 3)\n\n# Load and preprocess the dataset\nX, y = load_dataset(train_path, target_shape)\n\n# Split the dataset into training, testing, and validation sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n\nprint(\"Shape of X_train, y_train:\", X_train.shape, y_train.shape)\nprint(\"Shape of X_test, y_test:\", X_test.shape, y_test.shape)\nprint(\"Shape of X_val, y_val:\", X_val.shape, y_val.shape)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:48:46.517451Z","iopub.execute_input":"2023-07-23T11:48:46.518549Z","iopub.status.idle":"2023-07-23T11:53:39.514285Z","shell.execute_reply.started":"2023-07-23T11:48:46.518514Z","shell.execute_reply":"2023-07-23T11:53:39.513288Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"libpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\nlibpng warning: Out of place sRGB chunk\n","output_type":"stream"},{"name":"stdout","text":"Shape of X_train, y_train: (15827, 95, 95, 3) (15827, 10)\nShape of X_test, y_test: (4397, 95, 95, 3) (4397, 10)\nShape of X_val, y_val: (1759, 95, 95, 3) (1759, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the DenseNet201 model\ndef create_densenet201_model(input_shape, num_classes):\n    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')\n    x = base_model.output\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=x)\n    return model\n\n# Load the DenseNet169 model\ndef create_densenet169_model(input_shape, num_classes):\n    base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')\n    x = base_model.output\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=x)\n    return model\n\n# Load the Xception model\ndef create_xception_model(input_shape, num_classes):\n    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')\n    x = base_model.output\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:53:39.515585Z","iopub.execute_input":"2023-07-23T11:53:39.516652Z","iopub.status.idle":"2023-07-23T11:53:39.527497Z","shell.execute_reply.started":"2023-07-23T11:53:39.516618Z","shell.execute_reply":"2023-07-23T11:53:39.526589Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Squeeze and Excitation block\ndef se_block(input, ratio=16):\n    filters = input.shape[-1]\n    x = GlobalAveragePooling2D()(input)\n    x = Dense(filters // ratio, activation='relu')(x)\n    x = Dense(filters, activation='sigmoid')(x)\n    x = Reshape((1, 1, filters))(x)\n    x = multiply([input, x])\n    return x\n\n# Create the DenseNet201 model with SE block\ninput_shape = (95, 95, 3)\nnum_classes = y_train.shape[1]\nmodel_dn201 = create_densenet201_model(input_shape, num_classes)\n\n# Add SE blocks to the model\nfor layer in model_dn201.layers:\n    if isinstance(layer, Conv2D):\n        se = se_block(layer.output)\n        model_dn201 = Model(inputs=model_dn201.input, outputs=se)\n\n# Create the DenseNet169 model with SE block\nmodel_dn169 = create_densenet169_model(input_shape, num_classes)\n\n# Add SE blocks to the model\nfor layer in model_dn169.layers:\n    if isinstance(layer, Conv2D):\n        se = se_block(layer.output)\n        model_dn169 = Model(inputs=model_dn169.input, outputs=se)\n\n# Create the Xception model with SE block\nmodel_xception = create_xception_model(input_shape, num_classes)\n\n# Add SE blocks to the model\nfor layer in model_xception.layers:\n    if isinstance(layer, Conv2D):\n        se = se_block(layer.output)\n        model_xception = Model(inputs=model_xception.input, outputs=se)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:53:39.530861Z","iopub.execute_input":"2023-07-23T11:53:39.531658Z","iopub.status.idle":"2023-07-23T11:54:15.039579Z","shell.execute_reply.started":"2023-07-23T11:53:39.531624Z","shell.execute_reply":"2023-07-23T11:54:15.038649Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n74836368/74836368 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n51877672/51877672 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.layers import concatenate\n\n# Merge the models using Squeeze and Excitation attention\ndef ensemble_model(models, model_input, num_classes):\n    outputs = [model(model_input) for model in models]\n    avg = concatenate([GlobalAveragePooling2D()(out) for out in outputs])\n    x = Dense(1024, activation='relu')(avg)\n    x = Dropout(0.5)(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    return Model(inputs=model_input, outputs=x)\n\n# Ensemble the models\nmodels = [model_dn201, model_dn169, model_xception]\nmodel_input = Input(shape=input_shape)\nnum_classes = y_train.shape[1]  # Number of classes in the dataset\nensemble = ensemble_model(models, model_input, num_classes)\n\n# Compile the ensemble model\nensemble.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001, epsilon=0.1), metrics=['accuracy'])\nensemble.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:54:15.041142Z","iopub.execute_input":"2023-07-23T11:54:15.041503Z","iopub.status.idle":"2023-07-23T11:54:18.436579Z","shell.execute_reply.started":"2023-07-23T11:54:15.041467Z","shell.execute_reply":"2023-07-23T11:54:18.435578Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model_377\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 95, 95, 3)]  0           []                               \n                                                                                                  \n model_200 (Functional)         (None, 3, 3, 32)     18314466    ['input_4[0][0]']                \n                                                                                                  \n model_369 (Functional)         (None, 3, 3, 32)     12636386    ['input_4[0][0]']                \n                                                                                                  \n model_376 (Functional)         (None, 3, 3, 1024)   14938008    ['input_4[0][0]']                \n                                                                                                  \n global_average_pooling2d_375 (  (None, 32)          0           ['model_200[0][0]']              \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n global_average_pooling2d_376 (  (None, 32)          0           ['model_369[0][0]']              \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n global_average_pooling2d_377 (  (None, 1024)        0           ['model_376[0][0]']              \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n concatenate (Concatenate)      (None, 1088)         0           ['global_average_pooling2d_375[0]\n                                                                 [0]',                            \n                                                                  'global_average_pooling2d_376[0]\n                                                                 [0]',                            \n                                                                  'global_average_pooling2d_377[0]\n                                                                 [0]']                            \n                                                                                                  \n dense_754 (Dense)              (None, 1024)         1115136     ['concatenate[0][0]']            \n                                                                                                  \n dropout_3 (Dropout)            (None, 1024)         0           ['dense_754[0][0]']              \n                                                                                                  \n dense_755 (Dense)              (None, 10)           10250       ['dropout_3[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 47,014,246\nTrainable params: 46,592,150\nNon-trainable params: 422,096\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up a checkpoint to save the best model\ncheckpoint = ModelCheckpoint('/kaggle/working/ensemble_model.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=True)\n\n# Set up early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=25, min_delta=0.001)\n\n# Train the ensemble model\nhistory = ensemble.fit(X_train, y_train,\n                       epochs=35,\n                       batch_size=6,\n                       validation_data=(X_val, y_val),\n                       callbacks=[checkpoint, early_stopping])\n\n# Load the best weights\nensemble.load_weights('/kaggle/working/ensemble_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:54:18.438051Z","iopub.execute_input":"2023-07-23T11:54:18.438658Z","iopub.status.idle":"2023-07-23T14:48:49.562966Z","shell.execute_reply.started":"2023-07-23T11:54:18.438623Z","shell.execute_reply":"2023-07-23T14:48:49.561826Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/35\n2638/2638 [==============================] - 433s 142ms/step - loss: 1.0025 - accuracy: 0.6697 - val_loss: 0.8855 - val_accuracy: 0.8601\nEpoch 2/35\n2638/2638 [==============================] - 363s 138ms/step - loss: 0.4237 - accuracy: 0.8594 - val_loss: 0.3131 - val_accuracy: 0.9102\nEpoch 3/35\n2638/2638 [==============================] - 369s 140ms/step - loss: 0.2745 - accuracy: 0.9095 - val_loss: 0.2925 - val_accuracy: 0.9142\nEpoch 4/35\n2638/2638 [==============================] - 353s 134ms/step - loss: 0.1802 - accuracy: 0.9404 - val_loss: 0.2706 - val_accuracy: 0.9255\nEpoch 5/35\n2638/2638 [==============================] - 362s 137ms/step - loss: 0.1356 - accuracy: 0.9528 - val_loss: 0.2988 - val_accuracy: 0.9278\nEpoch 6/35\n2638/2638 [==============================] - 356s 135ms/step - loss: 0.1076 - accuracy: 0.9645 - val_loss: 0.2904 - val_accuracy: 0.9238\nEpoch 7/35\n2638/2638 [==============================] - 363s 138ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 0.2965 - val_accuracy: 0.9312\nEpoch 8/35\n2638/2638 [==============================] - 349s 132ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.2958 - val_accuracy: 0.9295\nEpoch 9/35\n2638/2638 [==============================] - 361s 137ms/step - loss: 0.0555 - accuracy: 0.9829 - val_loss: 0.2931 - val_accuracy: 0.9352\nEpoch 10/35\n2638/2638 [==============================] - 360s 136ms/step - loss: 0.0513 - accuracy: 0.9834 - val_loss: 0.2823 - val_accuracy: 0.9426\nEpoch 11/35\n2638/2638 [==============================] - 356s 135ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.3151 - val_accuracy: 0.9341\nEpoch 12/35\n2638/2638 [==============================] - 359s 136ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.3186 - val_accuracy: 0.9403\nEpoch 13/35\n2638/2638 [==============================] - 362s 137ms/step - loss: 0.0368 - accuracy: 0.9873 - val_loss: 0.3064 - val_accuracy: 0.9380\nEpoch 14/35\n2638/2638 [==============================] - 362s 137ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.3669 - val_accuracy: 0.9346\nEpoch 15/35\n2638/2638 [==============================] - 356s 135ms/step - loss: 0.0290 - accuracy: 0.9902 - val_loss: 0.3229 - val_accuracy: 0.9403\nEpoch 16/35\n2638/2638 [==============================] - 349s 132ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.2946 - val_accuracy: 0.9431\nEpoch 17/35\n2638/2638 [==============================] - 349s 132ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.3106 - val_accuracy: 0.9443\nEpoch 18/35\n2638/2638 [==============================] - 352s 133ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.3331 - val_accuracy: 0.9431\nEpoch 19/35\n2638/2638 [==============================] - 362s 137ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.3437 - val_accuracy: 0.9460\nEpoch 20/35\n2638/2638 [==============================] - 355s 135ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.3437 - val_accuracy: 0.9454\nEpoch 21/35\n2638/2638 [==============================] - 359s 136ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.3081 - val_accuracy: 0.9466\nEpoch 22/35\n2638/2638 [==============================] - 360s 137ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.3501 - val_accuracy: 0.9397\nEpoch 23/35\n2638/2638 [==============================] - 366s 139ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.3819 - val_accuracy: 0.9392\nEpoch 24/35\n2638/2638 [==============================] - 356s 135ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.3272 - val_accuracy: 0.9403\nEpoch 25/35\n2638/2638 [==============================] - 365s 138ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.3258 - val_accuracy: 0.9392\nEpoch 26/35\n2638/2638 [==============================] - 356s 135ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.3065 - val_accuracy: 0.9500\nEpoch 27/35\n2638/2638 [==============================] - 363s 138ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.3425 - val_accuracy: 0.9449\nEpoch 28/35\n2638/2638 [==============================] - 354s 134ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.3213 - val_accuracy: 0.9403\nEpoch 29/35\n2638/2638 [==============================] - 357s 136ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.3461 - val_accuracy: 0.9437\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the ensemble model on the test set\nval_loss, val_accuracy = ensemble.evaluate(X_test, y_test, verbose=0)\nprint(\"Test loss:\", val_loss)\nprint(\"Test accuracy:\", val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-23T14:48:49.566347Z","iopub.execute_input":"2023-07-23T14:48:49.566727Z","iopub.status.idle":"2023-07-23T14:49:08.288898Z","shell.execute_reply.started":"2023-07-23T14:48:49.566690Z","shell.execute_reply":"2023-07-23T14:49:08.287822Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test loss: 0.2629532217979431\nTest accuracy: 0.9490561485290527\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Get predictions on the test set\ny_pred = ensemble.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\n# Generate the classification report\nreport = classification_report(y_true_classes, y_pred_classes)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T14:54:21.002075Z","iopub.execute_input":"2023-07-23T14:54:21.003065Z","iopub.status.idle":"2023-07-23T14:54:49.916460Z","shell.execute_reply.started":"2023-07-23T14:54:21.003031Z","shell.execute_reply":"2023-07-23T14:54:49.915443Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"138/138 [==============================] - 19s 80ms/step\n              precision    recall  f1-score   support\n\n           0       0.92      0.93      0.92       346\n           1       0.94      0.96      0.95       792\n           2       0.96      0.95      0.95       235\n           3       0.90      0.99      0.94       421\n           4       0.97      0.93      0.95       185\n           5       0.95      0.90      0.93       132\n           6       0.97      0.90      0.94       389\n           7       0.94      0.96      0.95       387\n           8       0.99      0.98      0.99      1065\n           9       0.92      0.88      0.90       445\n\n    accuracy                           0.95      4397\n   macro avg       0.95      0.94      0.94      4397\nweighted avg       0.95      0.95      0.95      4397\n\n","output_type":"stream"}]}]}